{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training data into correct folders\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data/invasive-species-monitoring/train/non-invasive: File exists\n",
      "mkdir: data/invasive-species-monitoring/train/invasive: File exists\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "path = 'data/invasive-species-monitoring/'\n",
    "labels = np.genfromtxt(path + 'train_labels.csv', dtype=None, delimiter=',', names=True)\n",
    "%mkdir {path + 'train/non-invasive'}\n",
    "%mkdir {path + 'train/invasive'}\n",
    "\n",
    "for record in labels:\n",
    "    folder = 'invasive/' if np.int(record[1]) == 1 else 'non-invasive/'\n",
    "    %cp {path}train/{record[0]}.jpg {path}train/{folder}{record[0]}.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create validation set\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir -p {path + 'valid/invasive'}\n",
    "g = glob(path + 'train/invasive/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200):\n",
    "    %mv {shuf[i]} {path + 'valid/invasive/.'}\n",
    "    \n",
    "%mkdir -p {path + 'valid/non-invasive'}\n",
    "g = glob(path + 'train/non-invasive/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200): \n",
    "    %mv {shuf[i]} {path + 'valid/non-invasive/.'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sample dir\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir -p {path + 'sample/train/invasive'}\n",
    "g = glob(path + 'train/invasive/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(10):\n",
    "    %cp {shuf[i]} {path + 'sample/train/invasive/.'}\n",
    "\n",
    "%mkdir -p {path + 'sample/train/non-invasive'}\n",
    "g = glob(path + 'train/non-invasive/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(10):\n",
    "    %cp {shuf[i]} {path + 'sample/train/non-invasive/.'}\n",
    "\n",
    "%mkdir -p {path + 'sample/valid/invasive'}\n",
    "g = glob(path + 'valid/invasive/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(10):\n",
    "    %cp {shuf[i]} {path + 'sample/valid/invasive/.'}\n",
    "\n",
    "%mkdir -p {path + 'sample/valid/non-invasive'}\n",
    "g = glob(path + 'valid/non-invasive/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(10):\n",
    "    %cp {shuf[i]} {path + 'sample/valid/non-invasive/.'}\n",
    "    \n",
    "%mkdir -p {path + '/sample/test/unknown'}\n",
    "g = glob(path + 'test/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(10):\n",
    "    %cp {shuf[i]} {path + 'sample/test/unknown/.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to also move test data to a label \"unknown\"\n",
    "%mkdir -p {path + '/test/unknown'}\n",
    "%cp {path + 'test/*.jpg'} {path + 'test/unknown/.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/invasive-species-monitoring/sample/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/invasive-species-monitoring/sample/'\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()\n",
    "\n",
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size=64\n",
    "no_of_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 37 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Finetune the model\n",
    "batches = vgg.get_batches(path + '/train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path + '/valid', batch_size=batch_size*2)\n",
    "\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 51s - loss: 0.9457 - acc: 0.8750 - val_loss: 1.2576 - val_acc: 0.7568\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 50s - loss: 1.4464 - acc: 0.7750 - val_loss: 0.9198 - val_acc: 0.7838\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 50s - loss: 1.0671 - acc: 0.8750 - val_loss: 0.5901 - val_acc: 0.8919\n",
      "Running epoch: 3\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 50s - loss: 0.9976 - acc: 0.9000 - val_loss: 0.5439 - val_acc: 0.9189\n",
      "Running epoch: 4\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 51s - loss: 0.5413 - acc: 0.9250 - val_loss: 0.6502 - val_acc: 0.9189\n",
      "Completed 5 fit operations\n"
     ]
    }
   ],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "#latest_weights_filename = None\n",
    "vgg.model.load_weights(path + '/results' + latest_weights_filename)\n",
    "for epoch in range(no_of_epochs):\n",
    "    print('Running epoch: %d' % epoch)\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(path + '/results' + latest_weights_filename)\n",
    "print(\"Completed %s fit operations\" % no_of_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create prediction csv\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True \n",
    "batches, preds = vgg.test(path + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.6071e-09,   1.0000e+00],\n",
       "       [  1.1330e-14,   1.0000e+00],\n",
       "       [  9.9829e-01,   1.7142e-03],\n",
       "       [  3.3616e-01,   6.6384e-01],\n",
       "       [  6.9432e-04,   9.9931e-01]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown/114.jpg',\n",
       " 'unknown/1191.jpg',\n",
       " 'unknown/1342.jpg',\n",
       " 'unknown/1372.jpg',\n",
       " 'unknown/1412.jpg']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unknown/114.jpg', array([  7.6071e-09,   1.0000e+00], dtype=float32)),\n",
       " ('unknown/1191.jpg', array([  1.1330e-14,   1.0000e+00], dtype=float32)),\n",
       " ('unknown/1342.jpg', array([ 0.9983,  0.0017], dtype=float32)),\n",
       " ('unknown/1372.jpg', array([ 0.3362,  0.6638], dtype=float32)),\n",
       " ('unknown/1412.jpg', array([  6.9432e-04,   9.9931e-01], dtype=float32))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = zip(batches.filenames, preds)\n",
    "results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1400e+02,   2.5000e-02],\n",
       "       [  1.1910e+03,   2.5000e-02],\n",
       "       [  1.3420e+03,   9.7500e-01],\n",
       "       [  1.3720e+03,   3.3616e-01],\n",
       "       [  1.4120e+03,   2.5000e-02]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def format(x):\n",
    "    id = re.sub('unknown/([0-9]+)\\.jpg', r'\\1', x[0])\n",
    "    return [np.int(id), np.clip(np.float(x[1][0]), 0.025, 0.975)]\n",
    "    \n",
    "formattedResults = np.array(map(format, results))\n",
    "formattedResults[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('data/invasive-species-monitoring/jp_invasive.csv', formattedResults, fmt='%d,%.5f', delimiter=',', header='name,invasive', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/invasive-species-monitoring/jp_invasive.csv' target='_blank'>data/invasive-species-monitoring/jp_invasive.csv</a><br>"
      ],
      "text/plain": [
       "/Users/james/ai/fastai/deeplearning1/nbs/data/invasive-species-monitoring/jp_invasive.csv"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('data/invasive-species-monitoring/jp_invasive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
